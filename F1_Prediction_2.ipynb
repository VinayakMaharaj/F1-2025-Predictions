{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klIFVRnbfUC9",
        "outputId": "b56a51bb-7258-4525-ecd7-ccdd0b077271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.5.3]\n",
            "INFO:fastf1.fastf1.core:Loading data for Monaco Grand Prix - Race [v3.5.3]\n",
            "req            INFO \tUsing cached data for session_info\n",
            "INFO:fastf1.fastf1.req:Using cached data for session_info\n",
            "req            INFO \tUsing cached data for driver_info\n",
            "INFO:fastf1.fastf1.req:Using cached data for driver_info\n",
            "DEBUG:fastf1.ergast:Failed to parse timestamp '-1:53:44.819' in Ergastresponse.\n",
            "req            INFO \tUsing cached data for session_status_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for session_status_data\n",
            "req            INFO \tUsing cached data for lap_count\n",
            "INFO:fastf1.fastf1.req:Using cached data for lap_count\n",
            "req            INFO \tUsing cached data for track_status_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for track_status_data\n",
            "req            INFO \tUsing cached data for _extended_timing_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for _extended_timing_data\n",
            "req            INFO \tUsing cached data for timing_app_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for timing_app_data\n",
            "core           INFO \tProcessing timing data...\n",
            "INFO:fastf1.fastf1.core:Processing timing data...\n",
            "req            INFO \tUsing cached data for car_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for car_data\n",
            "req            INFO \tUsing cached data for position_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for position_data\n",
            "req            INFO \tUsing cached data for weather_data\n",
            "INFO:fastf1.fastf1.req:Using cached data for weather_data\n",
            "req            INFO \tUsing cached data for race_control_messages\n",
            "INFO:fastf1.fastf1.req:Using cached data for race_control_messages\n",
            "core           INFO \tFinished loading data for 20 drivers: ['1', '14', '31', '44', '63', '16', '10', '55', '4', '81', '77', '21', '24', '23', '22', '11', '27', '2', '20', '18']\n",
            "INFO:fastf1.fastf1.core:Finished loading data for 20 drivers: ['1', '14', '31', '44', '63', '16', '10', '55', '4', '81', '77', '21', '24', '23', '22', '11', '27', '2', '20', '18']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample lap data:\n",
            "  Driver                LapTime Compound  TyreLife TrackStatus\n",
            "1    VER 0 days 00:01:19.367000   MEDIUM       2.0           1\n",
            "2    VER 0 days 00:01:19.074000   MEDIUM       3.0           1\n",
            "3    VER 0 days 00:01:18.129000   MEDIUM       4.0           1\n",
            "4    VER 0 days 00:01:18.019000   MEDIUM       5.0           1\n",
            "5    VER 0 days 00:01:17.640000   MEDIUM       6.0           1\n",
            "Epoch 5, Loss: 0.2212\n",
            "Epoch 10, Loss: 0.0645\n",
            "Epoch 15, Loss: 0.0281\n",
            "Epoch 20, Loss: 0.0279\n",
            "Epoch 25, Loss: 0.0271\n",
            "Epoch 30, Loss: 0.0248\n",
            "Epoch 35, Loss: 0.0249\n",
            "Epoch 40, Loss: 0.0244\n",
            "Epoch 45, Loss: 0.0238\n",
            "Epoch 50, Loss: 0.0230\n",
            "\n",
            "Sample predictions vs actuals:\n",
            "Predicted: 77.97s | Actual: 78.24s\n",
            "Predicted: 77.96s | Actual: 78.36s\n",
            "Predicted: 78.01s | Actual: 78.00s\n",
            "Predicted: 78.04s | Actual: 78.03s\n",
            "Predicted: 77.95s | Actual: 78.01s\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“˜ F1 Prediction Project (2025 Edition)\n",
        "# FastF1 + XGBoost + SHAP + LSTM (PyTorch) with full normalization\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 1: SETUP & DEPENDENCIES\n",
        "# ----------------------------------------\n",
        "!pip install fastf1 xgboost shap matplotlib scikit-learn pandas --quiet\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import fastf1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 2: ENABLE CACHE & LOAD DATA\n",
        "# ----------------------------------------\n",
        "os.makedirs('/content/f1_cache', exist_ok=True)\n",
        "fastf1.Cache.enable_cache('/content/f1_cache')\n",
        "\n",
        "session = fastf1.get_session(2023, 'Monaco', 'R')\n",
        "session.load()\n",
        "\n",
        "laps = session.laps.pick_quicklaps().copy()\n",
        "print(\"Sample lap data:\")\n",
        "print(laps[['Driver', 'LapTime', 'Compound', 'TyreLife', 'TrackStatus']].head())\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 3: FEATURE ENGINEERING\n",
        "# ----------------------------------------\n",
        "columns = ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
        "sequence_length = 10\n",
        "\n",
        "laps = laps[['Driver', 'LapNumber', 'LapTime'] + columns].dropna()\n",
        "laps['LapTimeSec'] = laps['LapTime'].dt.total_seconds()\n",
        "\n",
        "# Normalize inputs\n",
        "feature_scaler = MinMaxScaler()\n",
        "laps[columns] = feature_scaler.fit_transform(laps[columns])\n",
        "\n",
        "# Normalize labels\n",
        "label_scaler = MinMaxScaler()\n",
        "laps['LapTimeSec'] = label_scaler.fit_transform(laps[['LapTimeSec']])\n",
        "\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for driver in laps['Driver'].unique():\n",
        "    driver_laps = laps[laps['Driver'] == driver].sort_values('LapNumber')\n",
        "    for i in range(len(driver_laps) - sequence_length):\n",
        "        seq = driver_laps.iloc[i:i+sequence_length][columns].values\n",
        "        label = driver_laps.iloc[i+sequence_length]['LapTimeSec']\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "\n",
        "X = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
        "y = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Split into train and test\n",
        "split_idx = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 4: LSTM MODEL\n",
        "# ----------------------------------------\n",
        "class LapTimeDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(LapTimeDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(LapTimeDataset(X_test, y_test), batch_size=32, shuffle=False)\n",
        "\n",
        "class LapPredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        self.norm = nn.BatchNorm1d(input_size)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size=64, batch_first=True)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        return self.head(h_n[-1])\n",
        "\n",
        "model = LapPredictor(input_size=X.shape[2])\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 5: TRAINING\n",
        "# ----------------------------------------\n",
        "model.train()\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ PART 6: EVALUATION\n",
        "# ----------------------------------------\n",
        "model.eval()\n",
        "preds = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        pred = model(xb)\n",
        "        preds.extend(pred.squeeze().tolist())\n",
        "        actuals.extend(yb.squeeze().tolist())\n",
        "\n",
        "# Inverse transform predictions\n",
        "preds = label_scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
        "actuals = label_scaler.inverse_transform(np.array(actuals).reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"\\nSample predictions vs actuals:\")\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {preds[i]:.2f}s | Actual: {actuals[i]:.2f}s\")\n"
      ]
    }
  ]
}